{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5mSUbEjK/ScbYwQaOs5S0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sayandeep27/Natural-Language-Processing/blob/main/Lyrics_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "_KGj7lmJe_W5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example expanded synthetic lyrics data\n",
        "lyrics_data = [\n",
        "    \"I'm feeling rough, I'm feeling raw, I'm in the prime of my life.\",\n",
        "    \"Let's make the most of the night like we're gonna die young.\",\n",
        "    \"Got a motel and built a fort out of sheets.\",\n",
        "    \"I had a dream so big and loud, I jumped so high I touched the clouds.\",\n",
        "    \"You can't stop me now, I'm ready for the fight.\",\n",
        "    \"We are the champions, my friends, and we'll keep on fighting till the end.\",\n",
        "    \"Wake me up before you go-go, don't leave me hanging on like a yo-yo.\",\n",
        "    \"I want to hold your hand, oh please say to me, you'll let me be your man.\",\n",
        "    \"Hey Jude, don't make it bad, take a sad song and make it better.\",\n",
        "    \"Here comes the sun, doo-doo-doo-doo, here comes the sun, and I say it's all right.\",\n",
        "    \"In the end, it doesn't even matter, I had to fall to lose it all.\",\n",
        "    \"We will, we will rock you, sing it now!\",\n",
        "    \"Imagine all the people living life in peace, you may say I'm a dreamer.\",\n",
        "    \"Just a small town girl, living in a lonely world, she took the midnight train going anywhere.\",\n",
        "    \"Don't stop believing, hold on to that feeling.\",\n",
        "    \"We found love in a hopeless place.\",\n",
        "    \"I kissed a girl and I liked it, the taste of her cherry chapstick.\",\n",
        "    \"Rolling in the deep, you had my heart inside of your hand.\",\n",
        "    \"All the single ladies, now put your hands up.\",\n",
        "    \"Every little thing she does is magic.\",\n",
        "    \"And I will always love you.\",\n",
        "    \"Oops, I did it again, I played with your heart.\",\n",
        "    \"Shake it off, shake it off.\",\n",
        "    \"Because you know I'm all about that bass, 'bout that bass, no treble.\",\n",
        "    \"We don't talk anymore, like we used to do.\",\n",
        "    \"I can't feel my face when I'm with you, but I love it.\",\n",
        "    \"Despacito, quiero respirar tu cuello despacito.\",\n",
        "    \"I got the eye of the tiger, a fighter, dancing through the fire.\",\n",
        "    \"I'm on the edge of glory, and I'm hanging on a moment of truth.\",\n",
        "    \"I see a little silhouetto of a man, Scaramouche, Scaramouche, will you do the Fandango?\",\n",
        "    \"Let it go, let it go, can't hold it back anymore.\",\n",
        "    \"I just want to tell you how I'm feeling, gotta make you understand.\"\n",
        "]\n",
        "\n",
        "# Combine all lyrics into a single string\n",
        "all_lyrics = \" \".join(lyrics_data)\n"
      ],
      "metadata": {
        "id": "cEblE2k7e_3F"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize words\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([all_lyrics])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in lyrics_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "# Convert label to categorical (one-hot encoding)\n",
        "label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n"
      ],
      "metadata": {
        "id": "iFZqU743fF0J"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model architecture with LSTM\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model_lstm.add(LSTM(150))\n",
        "model_lstm.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Model architecture with GRU\n",
        "model_gru = Sequential()\n",
        "model_gru.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model_gru.add(GRU(150))\n",
        "model_gru.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "tJ-46b-bfHUP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LSTM model\n",
        "model_lstm.fit(predictors, label, epochs=100, verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4H1r4dWkfLKR",
        "outputId": "c94bebd6-afeb-4cc0-aa43-d559f858c388"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 3s 33ms/step - loss: 5.2412 - accuracy: 0.0229\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 5.1170 - accuracy: 0.0487\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 4.9150 - accuracy: 0.0458\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 4.8460 - accuracy: 0.0573\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 4.8024 - accuracy: 0.0573\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 4.7731 - accuracy: 0.0573\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 1s 63ms/step - loss: 4.7496 - accuracy: 0.0573\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 1s 67ms/step - loss: 4.7057 - accuracy: 0.0544\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 4.6745 - accuracy: 0.0602\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 4.6134 - accuracy: 0.0716\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 4.5393 - accuracy: 0.0716\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 4.4619 - accuracy: 0.1060\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 4.3675 - accuracy: 0.0888\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 4.2513 - accuracy: 0.0888\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 4.0980 - accuracy: 0.1089\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 3.9685 - accuracy: 0.1175\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 3.8124 - accuracy: 0.1461\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 3.6855 - accuracy: 0.1662\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 3.4989 - accuracy: 0.2063\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 3.3566 - accuracy: 0.2235\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 3.2031 - accuracy: 0.2464\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 3.0530 - accuracy: 0.2923\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 2.9218 - accuracy: 0.3152\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 2.7756 - accuracy: 0.3553\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.6727 - accuracy: 0.3954\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 2.5242 - accuracy: 0.4499\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.4000 - accuracy: 0.4413\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 2.2892 - accuracy: 0.4756\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 2.2155 - accuracy: 0.4900\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 2.1122 - accuracy: 0.5158\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.9881 - accuracy: 0.5788\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 1.9053 - accuracy: 0.6132\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.8067 - accuracy: 0.6332\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 1.7222 - accuracy: 0.6762\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.6270 - accuracy: 0.6877\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 1.5562 - accuracy: 0.7221\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 1.4966 - accuracy: 0.7393\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 42ms/step - loss: 1.4385 - accuracy: 0.7622\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 1.3762 - accuracy: 0.8052\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.2923 - accuracy: 0.8138\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.2448 - accuracy: 0.8281\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 1s 68ms/step - loss: 1.1865 - accuracy: 0.8539\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 1s 62ms/step - loss: 1.1419 - accuracy: 0.8424\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 1.0843 - accuracy: 0.8682\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 1.0218 - accuracy: 0.8825\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 0s 37ms/step - loss: 0.9860 - accuracy: 0.8968\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.9303 - accuracy: 0.9083\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.8910 - accuracy: 0.9083\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.8434 - accuracy: 0.9140\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.8029 - accuracy: 0.9284\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 38ms/step - loss: 0.7691 - accuracy: 0.9255\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.7373 - accuracy: 0.9341\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.7118 - accuracy: 0.9398\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.6741 - accuracy: 0.9398\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.6460 - accuracy: 0.9484\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.6163 - accuracy: 0.9513\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.5908 - accuracy: 0.9484\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.5645 - accuracy: 0.9542\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.5389 - accuracy: 0.9570\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.5180 - accuracy: 0.9599\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4988 - accuracy: 0.9599\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4804 - accuracy: 0.9599\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4627 - accuracy: 0.9599\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.4428 - accuracy: 0.9628\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.4285 - accuracy: 0.9628\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.4129 - accuracy: 0.9628\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3989 - accuracy: 0.9628\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.3859 - accuracy: 0.9628\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.3705 - accuracy: 0.9599\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 0.3607 - accuracy: 0.9656\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 1s 66ms/step - loss: 0.3486 - accuracy: 0.9628\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 1s 64ms/step - loss: 0.3366 - accuracy: 0.9599\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 1s 65ms/step - loss: 0.3254 - accuracy: 0.9628\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 1s 71ms/step - loss: 0.3159 - accuracy: 0.9628\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 1s 52ms/step - loss: 0.3065 - accuracy: 0.9628\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2970 - accuracy: 0.9628\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2891 - accuracy: 0.9685\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2817 - accuracy: 0.9685\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2712 - accuracy: 0.9713\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2632 - accuracy: 0.9656\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2574 - accuracy: 0.9685\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2486 - accuracy: 0.9685\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2419 - accuracy: 0.9685\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2351 - accuracy: 0.9685\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2282 - accuracy: 0.9685\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2228 - accuracy: 0.9685\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2198 - accuracy: 0.9656\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2170 - accuracy: 0.9685\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2117 - accuracy: 0.9713\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.2064 - accuracy: 0.9685\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 0.2054 - accuracy: 0.9713\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2033 - accuracy: 0.9685\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.2135 - accuracy: 0.9656\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.2090 - accuracy: 0.9628\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.2201 - accuracy: 0.9628\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.2320 - accuracy: 0.9542\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.2113 - accuracy: 0.9599\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1952 - accuracy: 0.9628\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 35ms/step - loss: 0.1832 - accuracy: 0.9656\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1750 - accuracy: 0.9685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7856c8e73ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train GRU model\n",
        "model_gru.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sayoNQJCfPup",
        "outputId": "540ad3aa-bb42-48e1-8112-09330f791658"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 3s 29ms/step - loss: 5.2431 - accuracy: 0.0287\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 5.1919 - accuracy: 0.0659\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 4.9868 - accuracy: 0.0573\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 4.8580 - accuracy: 0.0573\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 0s 39ms/step - loss: 4.8016 - accuracy: 0.0573\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 4.7560 - accuracy: 0.0573\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 4.6969 - accuracy: 0.0573\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 1s 53ms/step - loss: 4.6490 - accuracy: 0.0659\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 4.5779 - accuracy: 0.0802\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 1s 59ms/step - loss: 4.4888 - accuracy: 0.0860\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 1s 51ms/step - loss: 4.3681 - accuracy: 0.1146\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 4.2033 - accuracy: 0.1576\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 4.0108 - accuracy: 0.1662\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 3.7974 - accuracy: 0.1862\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 3.5579 - accuracy: 0.2350\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 3.3191 - accuracy: 0.2808\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 3.0747 - accuracy: 0.3410\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 2.8272 - accuracy: 0.3696\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 2.5947 - accuracy: 0.4183\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 2.3704 - accuracy: 0.4585\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 2.1664 - accuracy: 0.4928\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.9584 - accuracy: 0.5530\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.7820 - accuracy: 0.6103\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 1.6137 - accuracy: 0.6934\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.4525 - accuracy: 0.7307\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 1.3056 - accuracy: 0.7622\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 1.1693 - accuracy: 0.8424\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 1.0459 - accuracy: 0.8567\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.9450 - accuracy: 0.8854\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.8500 - accuracy: 0.9140\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.7646 - accuracy: 0.9198\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.6895 - accuracy: 0.9284\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.6217 - accuracy: 0.9456\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.5642 - accuracy: 0.9456\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.5186 - accuracy: 0.9599\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4716 - accuracy: 0.9599\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.4321 - accuracy: 0.9542\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.4019 - accuracy: 0.9656\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3676 - accuracy: 0.9656\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.3438 - accuracy: 0.9628\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 0s 26ms/step - loss: 0.3212 - accuracy: 0.9656\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.3008 - accuracy: 0.9685\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 1s 48ms/step - loss: 0.2816 - accuracy: 0.9685\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.2641 - accuracy: 0.9685\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.2502 - accuracy: 0.9656\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 1s 55ms/step - loss: 0.2359 - accuracy: 0.9656\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 1s 58ms/step - loss: 0.2253 - accuracy: 0.9656\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 1s 50ms/step - loss: 0.2129 - accuracy: 0.9628\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.2065 - accuracy: 0.9628\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.1977 - accuracy: 0.9628\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1856 - accuracy: 0.9628\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.1801 - accuracy: 0.9656\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1729 - accuracy: 0.9656\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.1663 - accuracy: 0.9628\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1603 - accuracy: 0.9685\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.1568 - accuracy: 0.9685\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.1516 - accuracy: 0.9656\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.1460 - accuracy: 0.9656\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1428 - accuracy: 0.9656\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1390 - accuracy: 0.9656\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1355 - accuracy: 0.9628\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 0s 33ms/step - loss: 0.1321 - accuracy: 0.9656\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1280 - accuracy: 0.9685\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1256 - accuracy: 0.9656\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 0s 34ms/step - loss: 0.1232 - accuracy: 0.9628\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1197 - accuracy: 0.9656\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1187 - accuracy: 0.9628\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 0s 32ms/step - loss: 0.1163 - accuracy: 0.9656\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.1154 - accuracy: 0.9685\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.1142 - accuracy: 0.9656\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.1118 - accuracy: 0.9656\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1094 - accuracy: 0.9628\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.1087 - accuracy: 0.9628\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1045 - accuracy: 0.9628\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1039 - accuracy: 0.9628\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.1018 - accuracy: 0.9656\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.1022 - accuracy: 0.9656\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 0s 36ms/step - loss: 0.0992 - accuracy: 0.9656\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0987 - accuracy: 0.9656\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0977 - accuracy: 0.9713\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 1s 56ms/step - loss: 0.0965 - accuracy: 0.9685\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0946 - accuracy: 0.9685\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 1s 57ms/step - loss: 0.0945 - accuracy: 0.9685\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 1s 54ms/step - loss: 0.0920 - accuracy: 0.9713\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0920 - accuracy: 0.9656\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0918 - accuracy: 0.9685\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.0906 - accuracy: 0.9656\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0903 - accuracy: 0.9656\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0903 - accuracy: 0.9685\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 0s 31ms/step - loss: 0.0889 - accuracy: 0.9656\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0878 - accuracy: 0.9628\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0868 - accuracy: 0.9628\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0862 - accuracy: 0.9656\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0856 - accuracy: 0.9685\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 0s 28ms/step - loss: 0.0844 - accuracy: 0.9656\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 0s 30ms/step - loss: 0.0848 - accuracy: 0.9685\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 0s 27ms/step - loss: 0.0853 - accuracy: 0.9656\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0826 - accuracy: 0.9685\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0842 - accuracy: 0.9656\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 0s 29ms/step - loss: 0.0826 - accuracy: 0.9656\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7856bb7ed840>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted = np.argmax(predicted_probs, axis=-1)[0]\n",
        "\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Example usage\n",
        "seed_text = \"How are you\"\n",
        "generated_text_lstm = generate_text(seed_text, 6, model_lstm, max_sequence_len)\n",
        "generated_text_gru = generate_text(seed_text, 6, model_gru, max_sequence_len)\n",
        "\n",
        "print(\"Generated LSTM Text:\", generated_text_lstm)\n",
        "print(\"Generated GRU Text:\", generated_text_gru)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSBDodh7gejg",
        "outputId": "e98c6bdc-a947-4a07-a56a-8c737de768a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated LSTM Text: How are you rough i'm feeling raw i'm in\n",
            "Generated GRU Text: How are you know i'm all about that bass\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9zptkoETgsH4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}